
Welcome back, today we are going to look
at hashing which is another approach to
implementing symbol tables that can also
be very effective in practical
applications.
Here's our summary where we left off with
red black BST's where we could get
guaranteed logarithmic performance for a
broad range of symbol table operations,
and the question is can we do better than
that?
Is logarithmic performance the best we can
do?
And the answer is that actually we can,
but it's a different way of accessing the
data.
And also, it doesn't support ordered
operations.
But there's plenty of applications where
that extra speed for search and insert
that we can get this way is worthwhile.
The basic plan is to think of the symbol
table as really try to reduce the problem
to being like an array.
And what we do is use a function known as
a hash function that takes the key that
our symbol table key and reduces it to an
integer an array index and we use that
array index to store the key a-, and the
value in an array.
Maybe the value in a parallel array.
Now there's a lot issues in doing this.
First thing is we need to be able to
compute the hash function.
That is easy for some types of data, but
it can get complicated for more
complicated types of data.
Then the other thing is that instead of
doing comparative we're going to be doing
equality tests.
So we have to be sure we've got the method
that we want for checking whether two keys
are equal.
All we're gonna do is look in the table
and try to see if the key that's there is
equal to the key we're looking for.
And then there's th-, the problem of
collision resolution where since there are
so many possible values for a typical data
type, we're gonna get the situation where
two values hash to the same array index.
And we need a collision resolution
strategy to try to figure out what to do
in that case.
And these things are not difficult, but
they're all worth articulating as separate
issues that we have to deal with in order
to Get an effective symbol table
implementation.
Hashing really, at, at its core, is a
classic space-time tradeoff.
If we had no limitation on space at all,
then we could have a very huge array, with
space for, every possible key, and just
use the key itself as an index.
If our keys are 32 bit integer keys, and
we've got a table of size two to the
thirty-second, then we're just fine.
If there were no time limit contagion at
all, then just hash everything to the same
place and then do sequential search.
But sequential search can be slow when we
have lots of keys, so when patching is
kind of in the real word, where we're
trying to trade off this idea that we
don't have unlimited space and we also
don't have unlimited time, so we're trying
to find something in between.
So we'll look at hash functions, separate
chaining and then two collision resolution
methods called separate chaining and
linear probing.
Now look at the implementation of hash
functions.
So idealistically, what we'd like is to be
able to, take any key and uniformly
scramble it to produce a table index.
We have two requirements.
One is that, we have to be able to compute
the thing efficiently in a reasonable
amount of time.
And the other is that, it should be the
case that every table index is equally
likely for each key.
Now.
Mathematicians and computer scientists
have researched this problem in a lot of
detail and there's quite a bit known about
it.
But in practice this is something that
still we have to worry about somewhat.
So for example, let's suppose that our
keys are phone numbers.
Probably a bad idea to use the first three
digits of the phone number as a hash
function because so many phone numbers
will have the same area code, it's not
equally likely that each phone number has
the same first three digits.
You have a better chance using the last
three digits but actually in most cases
you want to find a way to use all the
data.
Another example is social security
numbers, again, not too good to use the
first three digits because they're
associated with some geographic region and
it's better to try and use the last three
digits.
And the real practical challenge with
hashing is that with developing hash
function, is that every type of key needs
a hash function, and you need a different
approach for every key type.
Now for standard keys like integers, and
strings, and doubles and so forth the, we
can count on the imple-, designer's and
implementer's job to implement good hash
functions, but if we're gonna be
implementing symbol with our own types of
data we're gonna have to worry about these
things in order to get a hash function
that's effective, that leads to an
effective symbol-table implementation.
So hashing is widely used for systems
programming and applications, so some
conventions for hashing are built into
Java.
In particular, all Java classes inherit a
method called hash code which is returns a
32 bit INT value.
And it's a requirement that if X and Y are
equal, then their hash codes should be
equal, so that's something that is a
convention that's built into Java and that
enables the hash code to be used for
hashing.
Also of course if they're not equal then
you'd like it, like it to be that their
hash codes are not equal, but you can't
always get that.
Now the default implementation for hashing
is the memory address of the object.
For hashing an object is the memory
address of an object.
So that kind of meets these two
requirements for Java.
The one that it doesn't maybe meet is the
idea that every table position should be
equally likely.
You, so usually we'll do some more work to
try and make that one happen.
As far as the algorithms go, as far as the
rules go you could always return seventeen
That's legal.
It doesn't have this higher, highly
desirable attribute but everything would
compile.
So you have to be a little careful that
somebody isn't in there doing that.
And again, for important key types, that
lots of people are going to use.
Some care has gone into the design of hash
functions and the built-in
implementations.
So, that's where you, the sweet spot for
the use of hashing.
We're using a standard key type, where
some expert has implemented the hash
function, and you don't need the ordered
part of the symbol table implementations.
So again, if you're divining your own
type, you're on your own.
So let's just talk briefly about it.
So, the actual implementation for an int
value is just return the value.
For bullion.
Mm-hm.
[laugh] What is that?
[laugh] Is this writ-.
Okay, we got you.
[laugh].
That's what it does huh.
Okay, so this is to motivate why we have
to mess with it.
Okay, that's fine.
[laugh] Okay.
It's right here.
Okay.
So Java has, customized implementations
for the, standard, data types, that,
people would use for, simple table keys,
and that's the sweet spot for hashing,
where some expert has done implementation
of, of the hash code, and also your
application does not need ordering.
But for user defined types, you're on your
own.
And we'll talk a little bit about how to
implement hash codes.
So here's the Java library implementations
for a few standard types.
And, they, they are what they are, and
what we'll do is, with knowledge that
that's what the hash code is, we'll do
some extra work to try to get this extra
property that, every table position should
seem to be equally likely.
So if it's an integer, the hash code's
supposed to be.
32 bits.
The energy is supposed to be 32 bits so
they just returned the value.
If it's a billion they's pick out a couple
of particular values that they return, so
hashing a billion types, it, there's only
two different values so, well it's hard to
think what you really might want there.
For a double value this is the code they
convert to 64 bit in X or the most
significant 32 bits with the least
significant 32 bits.
This illustrates something that you wanna
do if you have a lot of bits you wanna try
to involve all the bits somehow in the
hash function.
And for strings it kind of creates the
string as a huge number.
And then it really computes the value of
that number, a mod 32.
It uses an arithmetic a way of evaluating
polynomial, or a number so-called Hern-,
Horner's Method, where for each digit I
just multiply, so it treats it as a base
31 number and to get to compute that whole
number you multiply 31 times what you have
so far and add the next digit.
And that's called Horner's Rule and if
you're familiar with it, fine, and if
you're not, you can look at this little
example and decide what it is.
And again, it involves all the characters
of the string in computing the hash
function.
So, and actually since strings are
immutable, what Java does is keep the hash
value in an instance variable so it only
gets computed once, and that is going to
be very effective for performance in lots
of applications so once it computes the
hash code, it stores it as an instance
variable and the next time you ask for the
hash code of that string, it'll just
provide it and that works because strings
are immutable.
So how about implementing a hash code for
our own type of data.
And so we might have a, our transaction
type might have a couple of instance
variables, a string, a date, and a double.
And we need to compute a hash code so
return a 32-bit value.
And again we want to try to make use of
all the pieces of data that we have.
And we also want to make use of the hash
code implementations for the types of data
that we're using.
So, one thing to do is to start out with
some small prime number.
And this kind of mimics Horner's method,
to just add in more data as we get it.
So we pick some other small prime number
and for each field, we multiply by 31 and
then add the hash code for that field.
So I put the reference type, you just use
the hash code so, who was the string?
So string has a hash code method so we add
that in and dates, when's the dates we add
that hash code, multiply by 31 and add
that hash code in.
Try to take all the bits and scramble all
the bits and use them, for primitive types
take the wrapper type and use the hash
code.
So that's simple example of implementing a
hash-code for our own type of data that
might include.
Several different types of instance
variables.
So that's the standard recipe.
Use the 31X plus Y rule to combine all the
fields.
If it's a primitive type, use the wrapper
hash code.
If the field's null, return zero.
If it's a reference type, use that hash
code and apply it re, recursively.
And if you have an array, you have to
apply it to each entry.
Or actually, Java implements that in the,
array, in its arrays, library.
So this recipe works pretty well in
practice, and it's used in, several, in
Java's libraries.
Now in theory, it's, possible to, do,
something that has the property that, that
all, positions are equally likely, it's
called universal hash functions, these
things exist but they're not so widely
applied in practice.
So the basic rule is, if you're computing
on your own try to use the whole key, but
consult an expert if you're seeing some
performance problems or you really want to
be certain in some performance critical
situation.
Now, What we get back from a hash code is
a int value that is between minus two to
the thirty-first and two to the
thirty-first minus one.
Now, what we need is, if we have a table
of size m an array of size m that we're
gonna use to store the keys, we need an n
value between zero and m-1.
And, the value m is maybe a power of two
or sometimes we pick, pick a prime because
of the way that we normally would c-.
Get the, the big hash code value down to
be a number between zero and M minus one
is to just do mod M.
And if mod, if M is a prime, then, then
fr, from math, modular arithmetic, we know
that, we're using all the bits in the
number, in that point, too.
Now, since the hash code can be negative,
this doesn't, quite work the way, this
arithmetic's implemented in, Java, 'cuz,
it's one in a billion times.
You really have to take the absolute value
of.
Well, sorry, you have to take the absolute
value because otherwise it would be
negative, you can't have a negative number
between zero and minus one, but even if
you take the absolute value, there's gonna
have minus two to the thirty-first is
possible, so you have to just take the 31
bits, get the hash code out, make it
positive and then mod M is the way to go.
The math doesn't quite work out right.
So anyway, that, code down at the bottom,
is, you can, use that as a template for,
what you might wanna do.
And that's what we do in order to, get the
hash code, to be a number between zero and
M minus one.
And, if M is prime, it gives us some
comfort that, we have, some possibility of
each table position, appearing with equal
likelihood.
So that's our assumption that each key is
equally likely to hash to an integer
between zero and minus one.
And this assumption again is with work is
possible to come close to this lots of
researchers have done good work to show
this.
So we'll assume that as a starting point.
And that allows us to model the situation
with the so-called bins and balls model
that directly relates the study of hash
functions to classical probability theory.
So we've got N bins, that's our that'sour
correspondence for our hash table, and we
got M balls, and some number of balls,
however many keys we have, and we'd throw
'''em uni-formally at random into M bins,
and these things are studied in classical
common rhetoric analysis.
For example there's the birthday problem,
which how many balls do you throw before
you find two hitting the same bin, when do
you get the first collision, and the
answer to that is it's about square root
of Pi M over two.
When does all the bins fill up, that's
call the coupon collector problem, after
about m, natural log m tosses, every bin
has at least one ball.
Those are just examples of classic results
from combinatorial analysis that help us
understand what happens when we do this,
which is what we're doing with hashing.
And we'll look at more advanced versions
of these problems when we want to study
hashing.
And, in particular, it's known that after
And you've thrown N balls into the N bins
then the most loaded bin has log N over
log N balls, so that's going to help us
get a handle on the performance of hashing
algorithms, while we get to the
implementations.
So this is just and example showing all
the words in a tale of two cities, using
the modular hashing function for strings
like the one that Java uses.
And they're pretty uniformly distributed.
That's the summary for hash functions.
